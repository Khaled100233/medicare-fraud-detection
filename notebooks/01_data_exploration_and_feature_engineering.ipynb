{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea262024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_data_exploration_and_feature_engineering.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daa921db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HEALTHCARE PROVIDER FRAUD DETECTION - DATA EXPLORATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"HEALTHCARE PROVIDER FRAUD DETECTION - DATA EXPLORATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('../reports/figures', exist_ok=True)\n",
    "os.makedirs('../models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95fb5f",
   "metadata": {},
   "source": [
    "# 0. Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667b273",
   "metadata": {},
   "source": [
    "# 1. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f1a2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. LOADING DATASETS...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Beneficiary Data: (138556, 25)\n",
      "✓ Inpatient Data: (40474, 30)\n",
      "✓ Outpatient Data: (517737, 27)\n",
      "✓ Labels Data: (5410, 2)\n",
      "\n",
      "--- Full Dataset Fraud Distribution ---\n",
      "PotentialFraud\n",
      "No     4904\n",
      "Yes     506\n",
      "Name: count, dtype: int64\n",
      "Fraud Percentage: 9.35%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n1. LOADING DATASETS...\")\n",
    "\n",
    "# Load all data from training files only\n",
    "beneficiary_data = pd.read_csv('../data/Train_Beneficiarydata-1542865627584.csv')\n",
    "inpatient_data = pd.read_csv('../data/Train_Inpatientdata-1542865627584.csv')\n",
    "outpatient_data = pd.read_csv('../data/Train_Outpatientdata-1542865627584.csv')\n",
    "labels_data = pd.read_csv('../data/Train-1542865627584.csv')\n",
    "\n",
    "print(f\"✓ Beneficiary Data: {beneficiary_data.shape}\")\n",
    "print(f\"✓ Inpatient Data: {inpatient_data.shape}\")\n",
    "print(f\"✓ Outpatient Data: {outpatient_data.shape}\")\n",
    "print(f\"✓ Labels Data: {labels_data.shape}\")\n",
    "\n",
    "# Check fraud distribution in full dataset\n",
    "print(f\"\\n--- Full Dataset Fraud Distribution ---\")\n",
    "print(labels_data['PotentialFraud'].value_counts())\n",
    "fraud_pct = (labels_data['PotentialFraud'] == 'Yes').sum() / len(labels_data) * 100\n",
    "print(f\"Fraud Percentage: {fraud_pct:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce48524",
   "metadata": {},
   "source": [
    "# 2. DATA STRUCTURE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a01e8b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. UNDERSTANDING DATA STRUCTURE...\n",
      "\n",
      "--- Beneficiary Data Sample ---\n",
      "      BeneID         DOB  DOD  Gender  Race RenalDiseaseIndicator  State  \\\n",
      "0  BENE11001  1943-01-01  NaN       1     1                     0     39   \n",
      "1  BENE11002  1936-09-01  NaN       2     1                     0     39   \n",
      "2  BENE11003  1936-08-01  NaN       1     1                     0     52   \n",
      "\n",
      "   County  NoOfMonths_PartACov  NoOfMonths_PartBCov  ...  \\\n",
      "0     230                   12                   12  ...   \n",
      "1     280                   12                   12  ...   \n",
      "2     590                   12                   12  ...   \n",
      "\n",
      "   ChronicCond_Depression  ChronicCond_Diabetes  ChronicCond_IschemicHeart  \\\n",
      "0                       1                     1                          1   \n",
      "1                       2                     2                          2   \n",
      "2                       2                     2                          1   \n",
      "\n",
      "   ChronicCond_Osteoporasis  ChronicCond_rheumatoidarthritis  \\\n",
      "0                         2                                1   \n",
      "1                         2                                2   \n",
      "2                         2                                2   \n",
      "\n",
      "   ChronicCond_stroke  IPAnnualReimbursementAmt  IPAnnualDeductibleAmt  \\\n",
      "0                   1                     36000                   3204   \n",
      "1                   2                         0                      0   \n",
      "2                   2                         0                      0   \n",
      "\n",
      "   OPAnnualReimbursementAmt  OPAnnualDeductibleAmt  \n",
      "0                        60                     70  \n",
      "1                        30                     50  \n",
      "2                        90                     40  \n",
      "\n",
      "[3 rows x 25 columns]\n",
      "\n",
      "Columns (25): ['BeneID', 'DOB', 'DOD', 'Gender', 'Race', 'RenalDiseaseIndicator', 'State', 'County', 'NoOfMonths_PartACov', 'NoOfMonths_PartBCov', 'ChronicCond_Alzheimer', 'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease', 'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression', 'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt']\n",
      "\n",
      "--- Inpatient Data Sample ---\n",
      "      BeneID   ClaimID ClaimStartDt  ClaimEndDt  Provider  \\\n",
      "0  BENE11001  CLM46614   2009-04-12  2009-04-18  PRV55912   \n",
      "1  BENE11001  CLM66048   2009-08-31  2009-09-02  PRV55907   \n",
      "2  BENE11001  CLM68358   2009-09-17  2009-09-20  PRV56046   \n",
      "\n",
      "   InscClaimAmtReimbursed AttendingPhysician OperatingPhysician  \\\n",
      "0                   26000          PHY390922                NaN   \n",
      "1                    5000          PHY318495          PHY318495   \n",
      "2                    5000          PHY372395                NaN   \n",
      "\n",
      "  OtherPhysician AdmissionDt  ... ClmDiagnosisCode_7  ClmDiagnosisCode_8  \\\n",
      "0            NaN  2009-04-12  ...               2724               19889   \n",
      "1            NaN  2009-08-31  ...                NaN                 NaN   \n",
      "2      PHY324689  2009-09-17  ...                NaN                 NaN   \n",
      "\n",
      "  ClmDiagnosisCode_9 ClmDiagnosisCode_10 ClmProcedureCode_1  \\\n",
      "0               5849                 NaN                NaN   \n",
      "1                NaN                 NaN             7092.0   \n",
      "2                NaN                 NaN                NaN   \n",
      "\n",
      "  ClmProcedureCode_2 ClmProcedureCode_3 ClmProcedureCode_4 ClmProcedureCode_5  \\\n",
      "0                NaN                NaN                NaN                NaN   \n",
      "1                NaN                NaN                NaN                NaN   \n",
      "2                NaN                NaN                NaN                NaN   \n",
      "\n",
      "  ClmProcedureCode_6  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "\n",
      "[3 rows x 30 columns]\n",
      "\n",
      "Columns (30): ['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider', 'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician', 'OtherPhysician', 'AdmissionDt', 'ClmAdmitDiagnosisCode', 'DeductibleAmtPaid', 'DischargeDt', 'DiagnosisGroupCode', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5', 'ClmProcedureCode_6']\n",
      "\n",
      "--- Outpatient Data Sample ---\n",
      "      BeneID    ClaimID ClaimStartDt  ClaimEndDt  Provider  \\\n",
      "0  BENE11002  CLM624349   2009-10-11  2009-10-11  PRV56011   \n",
      "1  BENE11003  CLM189947   2009-02-12  2009-02-12  PRV57610   \n",
      "2  BENE11003  CLM438021   2009-06-27  2009-06-27  PRV57595   \n",
      "\n",
      "   InscClaimAmtReimbursed AttendingPhysician OperatingPhysician  \\\n",
      "0                      30          PHY326117                NaN   \n",
      "1                      80          PHY362868                NaN   \n",
      "2                      10          PHY328821                NaN   \n",
      "\n",
      "  OtherPhysician ClmDiagnosisCode_1  ... ClmDiagnosisCode_9  \\\n",
      "0            NaN              78943  ...                NaN   \n",
      "1            NaN               6115  ...                NaN   \n",
      "2            NaN               2723  ...                NaN   \n",
      "\n",
      "  ClmDiagnosisCode_10 ClmProcedureCode_1 ClmProcedureCode_2  \\\n",
      "0                 NaN                NaN                NaN   \n",
      "1                 NaN                NaN                NaN   \n",
      "2                 NaN                NaN                NaN   \n",
      "\n",
      "  ClmProcedureCode_3 ClmProcedureCode_4 ClmProcedureCode_5 ClmProcedureCode_6  \\\n",
      "0                NaN                NaN                NaN                NaN   \n",
      "1                NaN                NaN                NaN                NaN   \n",
      "2                NaN                NaN                NaN                NaN   \n",
      "\n",
      "  DeductibleAmtPaid  ClmAdmitDiagnosisCode  \n",
      "0                 0                  56409  \n",
      "1                 0                  79380  \n",
      "2                 0                    NaN  \n",
      "\n",
      "[3 rows x 27 columns]\n",
      "\n",
      "Columns (27): ['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider', 'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician', 'OtherPhysician', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5', 'ClmProcedureCode_6', 'DeductibleAmtPaid', 'ClmAdmitDiagnosisCode']\n",
      "\n",
      "--- Labels Sample ---\n",
      "   Provider PotentialFraud\n",
      "0  PRV51001             No\n",
      "1  PRV51003            Yes\n",
      "2  PRV51004             No\n",
      "3  PRV51005            Yes\n",
      "4  PRV51007             No\n",
      "\n",
      "Columns: ['Provider', 'PotentialFraud']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. UNDERSTANDING DATA STRUCTURE...\")\n",
    "\n",
    "print(\"\\n--- Beneficiary Data Sample ---\")\n",
    "print(beneficiary_data.head(3))\n",
    "print(f\"\\nColumns ({len(beneficiary_data.columns)}): {beneficiary_data.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n--- Inpatient Data Sample ---\")\n",
    "print(inpatient_data.head(3))\n",
    "print(f\"\\nColumns ({len(inpatient_data.columns)}): {inpatient_data.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n--- Outpatient Data Sample ---\")\n",
    "print(outpatient_data.head(3))\n",
    "print(f\"\\nColumns ({len(outpatient_data.columns)}): {outpatient_data.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n--- Labels Sample ---\")\n",
    "print(labels_data.head())\n",
    "print(f\"\\nColumns: {labels_data.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01014b1e",
   "metadata": {},
   "source": [
    "\n",
    "# 3. DATA QUALITY ASSESSMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d85219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. DATA QUALITY ASSESSMENT...\n",
      "\n",
      "--- Beneficiary Data ---\n",
      "Shape: (138556, 25)\n",
      "Missing values:\n",
      "DOD    137135\n",
      "dtype: int64\n",
      "Duplicates: 0\n",
      "\n",
      "--- Inpatient Data ---\n",
      "Shape: (40474, 30)\n",
      "Missing values:\n",
      "AttendingPhysician       112\n",
      "OperatingPhysician     16644\n",
      "OtherPhysician         35784\n",
      "DeductibleAmtPaid        899\n",
      "ClmDiagnosisCode_2       226\n",
      "ClmDiagnosisCode_3       676\n",
      "ClmDiagnosisCode_4      1534\n",
      "ClmDiagnosisCode_5      2894\n",
      "ClmDiagnosisCode_6      4838\n",
      "ClmDiagnosisCode_7      7258\n",
      "ClmDiagnosisCode_8      9942\n",
      "ClmDiagnosisCode_9     13497\n",
      "ClmDiagnosisCode_10    36547\n",
      "ClmProcedureCode_1     17326\n",
      "ClmProcedureCode_2     35020\n",
      "ClmProcedureCode_3     39509\n",
      "ClmProcedureCode_4     40358\n",
      "ClmProcedureCode_5     40465\n",
      "ClmProcedureCode_6     40474\n",
      "dtype: int64\n",
      "Duplicates: 0\n",
      "\n",
      "--- Outpatient Data ---\n",
      "Shape: (517737, 27)\n",
      "Missing values:\n",
      "AttendingPhysician         1396\n",
      "OperatingPhysician       427120\n",
      "OtherPhysician           322691\n",
      "ClmDiagnosisCode_1        10453\n",
      "ClmDiagnosisCode_2       195380\n",
      "ClmDiagnosisCode_3       314480\n",
      "ClmDiagnosisCode_4       392141\n",
      "ClmDiagnosisCode_5       443393\n",
      "ClmDiagnosisCode_6       468981\n",
      "ClmDiagnosisCode_7       484776\n",
      "ClmDiagnosisCode_8       494825\n",
      "ClmDiagnosisCode_9       502899\n",
      "ClmDiagnosisCode_10      516654\n",
      "ClmProcedureCode_1       517575\n",
      "ClmProcedureCode_2       517701\n",
      "ClmProcedureCode_3       517733\n",
      "ClmProcedureCode_4       517735\n",
      "ClmProcedureCode_5       517737\n",
      "ClmProcedureCode_6       517737\n",
      "ClmAdmitDiagnosisCode    412312\n",
      "dtype: int64\n",
      "Missing values:\n",
      "AttendingPhysician         1396\n",
      "OperatingPhysician       427120\n",
      "OtherPhysician           322691\n",
      "ClmDiagnosisCode_1        10453\n",
      "ClmDiagnosisCode_2       195380\n",
      "ClmDiagnosisCode_3       314480\n",
      "ClmDiagnosisCode_4       392141\n",
      "ClmDiagnosisCode_5       443393\n",
      "ClmDiagnosisCode_6       468981\n",
      "ClmDiagnosisCode_7       484776\n",
      "ClmDiagnosisCode_8       494825\n",
      "ClmDiagnosisCode_9       502899\n",
      "ClmDiagnosisCode_10      516654\n",
      "ClmProcedureCode_1       517575\n",
      "ClmProcedureCode_2       517701\n",
      "ClmProcedureCode_3       517733\n",
      "ClmProcedureCode_4       517735\n",
      "ClmProcedureCode_5       517737\n",
      "ClmProcedureCode_6       517737\n",
      "ClmAdmitDiagnosisCode    412312\n",
      "dtype: int64\n",
      "Duplicates: 0\n",
      "\n",
      "--- Labels Data ---\n",
      "Shape: (5410, 2)\n",
      "No missing values\n",
      "Duplicates: 0\n",
      "Duplicates: 0\n",
      "\n",
      "--- Labels Data ---\n",
      "Shape: (5410, 2)\n",
      "No missing values\n",
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n3. DATA QUALITY ASSESSMENT...\")\n",
    "\n",
    "def assess_quality(df, name):\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"Missing values:\\n{missing[missing > 0]}\")\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "    print(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "assess_quality(beneficiary_data, \"Beneficiary Data\")\n",
    "assess_quality(inpatient_data, \"Inpatient Data\")\n",
    "assess_quality(outpatient_data, \"Outpatient Data\")\n",
    "assess_quality(labels_data, \"Labels Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2379ef9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 4. KEY RELATIONSHIP ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43b6440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. ANALYZING RELATIONSHIPS...\n",
      "Unique Beneficiaries: 138556\n",
      "Unique Providers in Inpatient: 2092\n",
      "Unique Providers in Outpatient: 5012\n",
      "Unique Providers in Labels: 5410\n",
      "Avg Inpatient claims/provider: 19.35\n",
      "Avg Outpatient claims/provider: 103.30\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. ANALYZING RELATIONSHIPS...\")\n",
    "\n",
    "print(f\"Unique Beneficiaries: {beneficiary_data['BeneID'].nunique()}\")\n",
    "print(f\"Unique Providers in Inpatient: {inpatient_data['Provider'].nunique()}\")\n",
    "print(f\"Unique Providers in Outpatient: {outpatient_data['Provider'].nunique()}\")\n",
    "print(f\"Unique Providers in Labels: {labels_data['Provider'].nunique()}\")\n",
    "print(f\"Avg Inpatient claims/provider: {len(inpatient_data) / inpatient_data['Provider'].nunique():.2f}\")\n",
    "print(f\"Avg Outpatient claims/provider: {len(outpatient_data) / outpatient_data['Provider'].nunique():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4eca33",
   "metadata": {},
   "source": [
    "\n",
    "# 5. FEATURE ENGINEERING FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5860798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. DEFINING FEATURE ENGINEERING FUNCTIONS...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n5. DEFINING FEATURE ENGINEERING FUNCTIONS...\")\n",
    "\n",
    "def create_beneficiary_features(bene_df):\n",
    "    \"\"\"Aggregate beneficiary characteristics\"\"\"\n",
    "    \n",
    "    features = pd.DataFrame()\n",
    "    features['BeneID'] = bene_df['BeneID']\n",
    "    \n",
    "    # Demographics\n",
    "    if 'Gender' in bene_df.columns:\n",
    "        features['Gender'] = bene_df['Gender']\n",
    "    \n",
    "    if 'Race' in bene_df.columns:\n",
    "        features['Race'] = bene_df['Race']\n",
    "    \n",
    "    # Age calculation\n",
    "    if 'DOB' in bene_df.columns:\n",
    "        bene_df['DOB'] = pd.to_datetime(bene_df['DOB'], errors='coerce')\n",
    "        reference_date = pd.to_datetime('2009-12-01')\n",
    "        features['Age'] = (reference_date - bene_df['DOB']).dt.days / 365.25\n",
    "    \n",
    "    # Count chronic conditions\n",
    "    chronic_cols = [col for col in bene_df.columns if 'Chronic' in col]\n",
    "    if chronic_cols:\n",
    "        features['ChronicConditionsCount'] = bene_df[chronic_cols].sum(axis=1)\n",
    "    \n",
    "    # Renal disease indicator\n",
    "    if 'RenalDiseaseIndicator' in bene_df.columns:\n",
    "        features['HasRenalDisease'] = bene_df['RenalDiseaseIndicator'].map({'Y': 1, '0': 0}).fillna(0)\n",
    "    \n",
    "    # Is deceased\n",
    "    if 'DOD' in bene_df.columns:\n",
    "        features['IsDeceased'] = bene_df['DOD'].notna().astype(int)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def aggregate_claims(claims_df, claim_type):\n",
    "    \"\"\"Aggregate claim-level data to provider level\"\"\"\n",
    "    \n",
    "    provider_features = []\n",
    "    \n",
    "    for provider, group in claims_df.groupby('Provider'):\n",
    "        features = {'Provider': provider}\n",
    "        \n",
    "        # Basic claim statistics\n",
    "        features[f'{claim_type}_NumClaims'] = len(group)\n",
    "        features[f'{claim_type}_NumBeneficiaries'] = group['BeneID'].nunique()\n",
    "        features[f'{claim_type}_AvgClaimsPerBeneficiary'] = len(group) / group['BeneID'].nunique()\n",
    "        \n",
    "        # Financial features\n",
    "        if 'InscClaimAmtReimbursed' in group.columns:\n",
    "            features[f'{claim_type}_TotalReimbursed'] = group['InscClaimAmtReimbursed'].sum()\n",
    "            features[f'{claim_type}_AvgReimbursed'] = group['InscClaimAmtReimbursed'].mean()\n",
    "            features[f'{claim_type}_StdReimbursed'] = group['InscClaimAmtReimbursed'].std()\n",
    "            features[f'{claim_type}_MaxReimbursed'] = group['InscClaimAmtReimbursed'].max()\n",
    "            features[f'{claim_type}_MinReimbursed'] = group['InscClaimAmtReimbursed'].min()\n",
    "        \n",
    "        if 'DeductibleAmtPaid' in group.columns:\n",
    "            features[f'{claim_type}_TotalDeductible'] = group['DeductibleAmtPaid'].sum()\n",
    "            features[f'{claim_type}_AvgDeductible'] = group['DeductibleAmtPaid'].mean()\n",
    "        \n",
    "        # Physician statistics\n",
    "        physician_cols = [col for col in group.columns if 'Physician' in col]\n",
    "        if physician_cols:\n",
    "            features[f'{claim_type}_NumUniquePhysicians'] = group[physician_cols].nunique().sum()\n",
    "        \n",
    "        # Diagnosis codes\n",
    "        diag_cols = [col for col in group.columns if 'ClmDiagnosisCode' in col]\n",
    "        if diag_cols:\n",
    "            unique_diagnoses = set()\n",
    "            for col in diag_cols:\n",
    "                unique_diagnoses.update(group[col].dropna().unique())\n",
    "            features[f'{claim_type}_UniqueDiagnoses'] = len(unique_diagnoses)\n",
    "        \n",
    "        # Procedure codes\n",
    "        proc_cols = [col for col in group.columns if 'ClmProcedureCode' in col]\n",
    "        if proc_cols:\n",
    "            unique_procedures = set()\n",
    "            for col in proc_cols:\n",
    "                unique_procedures.update(group[col].dropna().unique())\n",
    "            features[f'{claim_type}_UniqueProcedures'] = len(unique_procedures)\n",
    "        \n",
    "        # Admission duration (for inpatient only)\n",
    "        if claim_type == 'Inpatient' and 'AdmissionDt' in group.columns and 'DischargeDt' in group.columns:\n",
    "            group['AdmissionDt'] = pd.to_datetime(group['AdmissionDt'], errors='coerce')\n",
    "            group['DischargeDt'] = pd.to_datetime(group['DischargeDt'], errors='coerce')\n",
    "            group['LOS'] = (group['DischargeDt'] - group['AdmissionDt']).dt.days\n",
    "            features[f'{claim_type}_AvgLOS'] = group['LOS'].mean()\n",
    "            features[f'{claim_type}_TotalLOS'] = group['LOS'].sum()\n",
    "            features[f'{claim_type}_MaxLOS'] = group['LOS'].max()\n",
    "        \n",
    "        # Claim dates analysis\n",
    "        if 'ClaimStartDt' in group.columns and 'ClaimEndDt' in group.columns:\n",
    "            group['ClaimStartDt'] = pd.to_datetime(group['ClaimStartDt'], errors='coerce')\n",
    "            group['ClaimEndDt'] = pd.to_datetime(group['ClaimEndDt'], errors='coerce')\n",
    "            group['ClaimDuration'] = (group['ClaimEndDt'] - group['ClaimStartDt']).dt.days\n",
    "            features[f'{claim_type}_AvgClaimDuration'] = group['ClaimDuration'].mean()\n",
    "        \n",
    "        provider_features.append(features)\n",
    "    \n",
    "    return pd.DataFrame(provider_features)\n",
    "\n",
    "def aggregate_bene_by_provider(claims_df, bene_features):\n",
    "    \"\"\"Aggregate beneficiary characteristics at provider level\"\"\"\n",
    "    \n",
    "    # Merge claims with beneficiary features\n",
    "    claims_with_bene = claims_df.merge(bene_features, on='BeneID', how='left')\n",
    "    \n",
    "    # Aggregate by provider\n",
    "    agg_dict = {}\n",
    "    \n",
    "    if 'Age' in claims_with_bene.columns:\n",
    "        agg_dict['Age'] = ['mean', 'std', 'min', 'max']\n",
    "    if 'Gender' in claims_with_bene.columns:\n",
    "        agg_dict['Gender'] = 'mean'\n",
    "    if 'ChronicConditionsCount' in claims_with_bene.columns:\n",
    "        agg_dict['ChronicConditionsCount'] = ['mean', 'max', 'sum']\n",
    "    if 'IsDeceased' in claims_with_bene.columns:\n",
    "        agg_dict['IsDeceased'] = 'sum'\n",
    "    if 'HasRenalDisease' in claims_with_bene.columns:\n",
    "        agg_dict['HasRenalDisease'] = 'sum'\n",
    "    \n",
    "    if not agg_dict:\n",
    "        return pd.DataFrame({'Provider': claims_df['Provider'].unique()})\n",
    "    \n",
    "    provider_bene = claims_df.merge(bene_features, on='BeneID', how='left')\\\n",
    "                              .groupby('Provider').agg(agg_dict).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    provider_bene.columns = ['_'.join(col).strip('_') if col[1] else col[0] \n",
    "                             for col in provider_bene.columns.values]\n",
    "    \n",
    "    return provider_bene\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f8b78",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 6. PROCESS TRAINING DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab2a2ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. PROCESSING DATA AND CREATING FEATURES...\n",
      "Creating beneficiary features...\n",
      "Aggregating inpatient claims...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating outpatient claims...\n",
      "Aggregating beneficiary info by provider (inpatient)...\n",
      "Aggregating beneficiary info by provider (outpatient)...\n",
      "Aggregating beneficiary info by provider (inpatient)...\n",
      "Aggregating beneficiary info by provider (outpatient)...\n",
      "Merging all provider features...\n",
      "\n",
      "✓ Full provider dataset: (5410, 53)\n",
      "✓ Features created: 51\n",
      "Merging all provider features...\n",
      "\n",
      "✓ Full provider dataset: (5410, 53)\n",
      "✓ Features created: 51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n6. PROCESSING DATA AND CREATING FEATURES...\")\n",
    "\n",
    "print(\"Creating beneficiary features...\")\n",
    "bene_features = create_beneficiary_features(beneficiary_data)\n",
    "\n",
    "print(\"Aggregating inpatient claims...\")\n",
    "inpatient_features = aggregate_claims(inpatient_data, 'Inpatient')\n",
    "\n",
    "print(\"Aggregating outpatient claims...\")\n",
    "outpatient_features = aggregate_claims(outpatient_data, 'Outpatient')\n",
    "\n",
    "print(\"Aggregating beneficiary info by provider (inpatient)...\")\n",
    "inpatient_bene = aggregate_bene_by_provider(inpatient_data, bene_features)\n",
    "\n",
    "print(\"Aggregating beneficiary info by provider (outpatient)...\")\n",
    "outpatient_bene = aggregate_bene_by_provider(outpatient_data, bene_features)\n",
    "\n",
    "# Merge all features\n",
    "print(\"Merging all provider features...\")\n",
    "provider_data = labels_data.copy()\n",
    "provider_data = provider_data.merge(inpatient_features, on='Provider', how='left')\n",
    "provider_data = provider_data.merge(outpatient_features, on='Provider', how='left')\n",
    "provider_data = provider_data.merge(inpatient_bene, on='Provider', how='left')\n",
    "provider_data = provider_data.merge(outpatient_bene, on='Provider', how='left', \n",
    "                                    suffixes=('_Inp', '_Out'))\n",
    "\n",
    "# Fill NaN (providers with no claims in one category)\n",
    "provider_data = provider_data.fillna(0)\n",
    "\n",
    "print(f\"\\n✓ Full provider dataset: {provider_data.shape}\")\n",
    "print(f\"✓ Features created: {provider_data.shape[1] - 2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf6fd0c",
   "metadata": {},
   "source": [
    "\n",
    "# 7. SPLIT DATA INTO TRAIN AND TEST SETS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52f71b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. SPLITTING DATA INTO TRAIN AND TEST SETS...\n",
      "\n",
      "✓ Training provider dataset: (4328, 53)\n",
      "✓ Test provider dataset: (1082, 53)\n",
      "\n",
      "--- Training Set Distribution ---\n",
      "PotentialFraud\n",
      "No     3923\n",
      "Yes     405\n",
      "Name: count, dtype: int64\n",
      "Fraud Percentage: 9.36%\n",
      "\n",
      "--- Test Set Distribution ---\n",
      "PotentialFraud\n",
      "No     981\n",
      "Yes    101\n",
      "Name: count, dtype: int64\n",
      "Fraud Percentage: 9.33%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n7. SPLITTING DATA INTO TRAIN AND TEST SETS...\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split provider data into train and test (80/20 split)\n",
    "train_provider_data, test_provider_data = train_test_split(\n",
    "    provider_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=provider_data['PotentialFraud']\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Training provider dataset: {train_provider_data.shape}\")\n",
    "print(f\"✓ Test provider dataset: {test_provider_data.shape}\")\n",
    "\n",
    "# Check fraud distribution in both sets\n",
    "train_fraud_counts = train_provider_data['PotentialFraud'].value_counts()\n",
    "test_fraud_counts = test_provider_data['PotentialFraud'].value_counts()\n",
    "\n",
    "print(f\"\\n--- Training Set Distribution ---\")\n",
    "print(train_fraud_counts)\n",
    "print(f\"Fraud Percentage: {(train_fraud_counts.get('Yes', 0) / len(train_provider_data) * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\n--- Test Set Distribution ---\")\n",
    "print(test_fraud_counts)\n",
    "print(f\"Fraud Percentage: {(test_fraud_counts.get('Yes', 0) / len(test_provider_data) * 100):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fea74",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 8. EXPLORATORY DATA ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f14c7525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8. EXPLORATORY DATA ANALYSIS...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: target_distribution.png\n",
      "✓ Saved: fraud_comparison.png\n",
      "✓ Saved: fraud_comparison.png\n",
      "✓ Saved: correlation_heatmap.png\n",
      "✓ Saved: correlation_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n8. EXPLORATORY DATA ANALYSIS...\")\n",
    "\n",
    "# Target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "train_fraud_counts = train_provider_data['PotentialFraud'].value_counts()\n",
    "axes[0].bar(train_fraud_counts.index, train_fraud_counts.values, color=['green', 'red'])\n",
    "axes[0].set_title('Training Set - Fraud Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Potential Fraud')\n",
    "axes[0].set_ylabel('Count')\n",
    "for i, v in enumerate(train_fraud_counts.values):\n",
    "    axes[0].text(i, v + 20, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "test_fraud_counts = test_provider_data['PotentialFraud'].value_counts()\n",
    "axes[1].bar(test_fraud_counts.index, test_fraud_counts.values, color=['green', 'red'])\n",
    "axes[1].set_title('Test Set - Fraud Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Potential Fraud')\n",
    "axes[1].set_ylabel('Count')\n",
    "for i, v in enumerate(test_fraud_counts.values):\n",
    "    axes[1].text(i, v + 20, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: target_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# Fraud comparison - key metrics\n",
    "fraud_yes = train_provider_data[train_provider_data['PotentialFraud'] == 'Yes']\n",
    "fraud_no = train_provider_data[train_provider_data['PotentialFraud'] == 'No']\n",
    "\n",
    "numeric_cols = train_provider_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Select key comparison metrics\n",
    "comparison_metrics = [col for col in [\n",
    "    'Inpatient_TotalReimbursed', 'Outpatient_TotalReimbursed',\n",
    "    'Inpatient_NumClaims', 'Outpatient_NumClaims',\n",
    "    'Age_mean_Inp', 'IsDeceased_sum_Inp'\n",
    "] if col in numeric_cols]\n",
    "\n",
    "if len(comparison_metrics) >= 6:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, col in enumerate(comparison_metrics[:6]):\n",
    "        axes[i].boxplot([fraud_no[col].dropna(), fraud_yes[col].dropna()], \n",
    "                       labels=['No Fraud', 'Fraud'])\n",
    "        axes[i].set_title(col, fontweight='bold')\n",
    "        axes[i].set_ylabel('Value')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/figures/fraud_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"✓ Saved: fraud_comparison.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Correlation heatmap\n",
    "if len(numeric_cols) > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = train_provider_data[numeric_cols].corr()\n",
    "    n_features = min(20, len(numeric_cols))\n",
    "    sns.heatmap(correlation_matrix.iloc[:n_features, :n_features], \n",
    "               annot=False, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/figures/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"✓ Saved: correlation_heatmap.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ea8c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 9. SAVE PROCESSED DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88ca2b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9. SAVING PROCESSED DATA...\n",
      "✓ Saved: processed_train_provider_data.csv\n",
      "✓ Saved: processed_test_provider_data.csv\n",
      "\n",
      "================================================================================\n",
      "DATA EXPLORATION COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Full Dataset Summary:\n",
      "  Total Providers: 5410\n",
      "  Total Features: 51\n",
      "\n",
      "Training Dataset Summary:\n",
      "  Total Providers: 4328\n",
      "  Fraudulent: 405 (9.36%)\n",
      "  Legitimate: 3923 (90.64%)\n",
      "  Total Features: 51\n",
      "\n",
      "Test Dataset Summary:\n",
      "  Total Providers: 1082\n",
      "  Fraudulent: 101 (9.33%)\n",
      "  Legitimate: 981 (90.67%)\n",
      "  Total Features: 51\n",
      "\n",
      "Next Step: Run 02_modeling.ipynb\n",
      "✓ Saved: processed_train_provider_data.csv\n",
      "✓ Saved: processed_test_provider_data.csv\n",
      "\n",
      "================================================================================\n",
      "DATA EXPLORATION COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Full Dataset Summary:\n",
      "  Total Providers: 5410\n",
      "  Total Features: 51\n",
      "\n",
      "Training Dataset Summary:\n",
      "  Total Providers: 4328\n",
      "  Fraudulent: 405 (9.36%)\n",
      "  Legitimate: 3923 (90.64%)\n",
      "  Total Features: 51\n",
      "\n",
      "Test Dataset Summary:\n",
      "  Total Providers: 1082\n",
      "  Fraudulent: 101 (9.33%)\n",
      "  Legitimate: 981 (90.67%)\n",
      "  Total Features: 51\n",
      "\n",
      "Next Step: Run 02_modeling.ipynb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n9. SAVING PROCESSED DATA...\")\n",
    "\n",
    "train_provider_data.to_csv('../data/processed_train_provider_data.csv', index=False)\n",
    "test_provider_data.to_csv('../data/processed_test_provider_data.csv', index=False)\n",
    "\n",
    "print(\"✓ Saved: processed_train_provider_data.csv\")\n",
    "print(\"✓ Saved: processed_test_provider_data.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA EXPLORATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nFull Dataset Summary:\")\n",
    "print(f\"  Total Providers: {len(provider_data)}\")\n",
    "print(f\"  Total Features: {provider_data.shape[1] - 2}\")\n",
    "\n",
    "print(f\"\\nTraining Dataset Summary:\")\n",
    "print(f\"  Total Providers: {len(train_provider_data)}\")\n",
    "print(f\"  Fraudulent: {len(fraud_yes)} ({len(fraud_yes)/len(train_provider_data)*100:.2f}%)\")\n",
    "print(f\"  Legitimate: {len(fraud_no)} ({len(fraud_no)/len(train_provider_data)*100:.2f}%)\")\n",
    "print(f\"  Total Features: {len(numeric_cols)}\")\n",
    "\n",
    "print(f\"\\nTest Dataset Summary:\")\n",
    "print(f\"  Total Providers: {len(test_provider_data)}\")\n",
    "print(f\"  Fraudulent: {test_fraud_counts.get('Yes', 0)} ({test_fraud_counts.get('Yes', 0)/len(test_provider_data)*100:.2f}%)\")\n",
    "print(f\"  Legitimate: {test_fraud_counts.get('No', 0)} ({test_fraud_counts.get('No', 0)/len(test_provider_data)*100:.2f}%)\")\n",
    "print(f\"  Total Features: {test_provider_data.shape[1] - 2}\")\n",
    "\n",
    "print(f\"\\nNext Step: Run 02_modeling.ipynb\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
