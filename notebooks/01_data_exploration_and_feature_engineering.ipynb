{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea262024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_data_exploration_and_feature_engineering.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa921db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"HEALTHCARE PROVIDER FRAUD DETECTION - DATA EXPLORATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('reports/figures', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667b273",
   "metadata": {},
   "source": [
    "# 1. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n1. LOADING DATASETS...\")\n",
    "\n",
    "# Load training datasets\n",
    "train_beneficiary = pd.read_csv('../data/Train_Beneficiarydata-1542865627584.csv')\n",
    "train_inpatient = pd.read_csv('../data/Train_Inpatientdata-1542865627584.csv')\n",
    "train_outpatient = pd.read_csv('../data/Train_Outpatientdata-1542865627584.csv')\n",
    "train_labels = pd.read_csv('../data/Train-1542865627584.csv')\n",
    "\n",
    "# Load test datasets\n",
    "test_beneficiary = pd.read_csv('../data/Test_Beneficiarydata-1542969243754.csv')\n",
    "test_inpatient = pd.read_csv('../data/Test_Inpatientdata-1542969243754.csv')\n",
    "test_outpatient = pd.read_csv('../data/Test_Outpatientdata-1542969243754.csv')\n",
    "test_labels = pd.read_csv('../data/Test-1542969243754.csv')\n",
    "\n",
    "print(f\"✓ Train Beneficiary: {train_beneficiary.shape}\")\n",
    "print(f\"✓ Train Inpatient: {train_inpatient.shape}\")\n",
    "print(f\"✓ Train Outpatient: {train_outpatient.shape}\")\n",
    "print(f\"✓ Train Labels: {train_labels.shape}\")\n",
    "print(f\"\\n✓ Test Beneficiary: {test_beneficiary.shape}\")\n",
    "print(f\"✓ Test Inpatient: {test_inpatient.shape}\")\n",
    "print(f\"✓ Test Outpatient: {test_outpatient.shape}\")\n",
    "print(f\"✓ Test Labels: {test_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce48524",
   "metadata": {},
   "source": [
    "# 2. DATA STRUCTURE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n2. UNDERSTANDING DATA STRUCTURE...\")\n",
    "\n",
    "print(\"\\n--- Beneficiary Data Sample ---\")\n",
    "print(train_beneficiary.head(3))\n",
    "print(f\"\\nColumns ({len(train_beneficiary.columns)}): {train_beneficiary.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n--- Inpatient Data Sample ---\")\n",
    "print(train_inpatient.head(3))\n",
    "print(f\"\\nColumns ({len(train_inpatient.columns)}): {train_inpatient.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n--- Outpatient Data Sample ---\")\n",
    "print(train_outpatient.head(3))\n",
    "print(f\"\\nColumns ({len(train_outpatient.columns)}): {train_outpatient.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n--- Labels Sample ---\")\n",
    "print(train_labels.head())\n",
    "print(f\"\\nColumns: {train_labels.columns.tolist()}\")\n",
    "\n",
    "# Check fraud distribution\n",
    "print(f\"\\n--- Training Set Fraud Distribution ---\")\n",
    "print(train_labels['PotentialFraud'].value_counts())\n",
    "fraud_pct = (train_labels['PotentialFraud'] == 'Yes').sum() / len(train_labels) * 100\n",
    "print(f\"Fraud Percentage: {fraud_pct:.2f}%\")\n",
    "\n",
    "print(f\"\\n--- Test Set Fraud Distribution ---\")\n",
    "print(test_labels['PotentialFraud'].value_counts())\n",
    "test_fraud_pct = (test_labels['PotentialFraud'] == 'Yes').sum() / len(test_labels) * 100\n",
    "print(f\"Fraud Percentage: {test_fraud_pct:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01014b1e",
   "metadata": {},
   "source": [
    "\n",
    "# 3. DATA QUALITY ASSESSMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d85219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n3. DATA QUALITY ASSESSMENT...\")\n",
    "\n",
    "def assess_quality(df, name):\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"Missing values:\\n{missing[missing > 0]}\")\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "    print(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n=== TRAINING DATA ===\")\n",
    "assess_quality(train_beneficiary, \"Train Beneficiary\")\n",
    "assess_quality(train_inpatient, \"Train Inpatient\")\n",
    "assess_quality(train_outpatient, \"Train Outpatient\")\n",
    "assess_quality(train_labels, \"Train Labels\")\n",
    "\n",
    "print(\"\\n=== TEST DATA ===\")\n",
    "assess_quality(test_beneficiary, \"Test Beneficiary\")\n",
    "assess_quality(test_inpatient, \"Test Inpatient\")\n",
    "assess_quality(test_outpatient, \"Test Outpatient\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2379ef9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 4. KEY RELATIONSHIP ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4. ANALYZING RELATIONSHIPS...\")\n",
    "\n",
    "print(\"\\n--- TRAINING DATA ---\")\n",
    "print(f\"Unique Beneficiaries: {train_beneficiary['BeneID'].nunique()}\")\n",
    "print(f\"Unique Providers in Inpatient: {train_inpatient['Provider'].nunique()}\")\n",
    "print(f\"Unique Providers in Outpatient: {train_outpatient['Provider'].nunique()}\")\n",
    "print(f\"Unique Providers in Labels: {train_labels['Provider'].nunique()}\")\n",
    "print(f\"Avg Inpatient claims/provider: {len(train_inpatient) / train_inpatient['Provider'].nunique():.2f}\")\n",
    "print(f\"Avg Outpatient claims/provider: {len(train_outpatient) / train_outpatient['Provider'].nunique():.2f}\")\n",
    "\n",
    "print(\"\\n--- TEST DATA ---\")\n",
    "print(f\"Unique Beneficiaries: {test_beneficiary['BeneID'].nunique()}\")\n",
    "print(f\"Unique Providers in Inpatient: {test_inpatient['Provider'].nunique()}\")\n",
    "print(f\"Unique Providers in Outpatient: {test_outpatient['Provider'].nunique()}\")\n",
    "print(f\"Unique Providers in Labels: {test_labels['Provider'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4eca33",
   "metadata": {},
   "source": [
    "\n",
    "# 5. FEATURE ENGINEERING FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n5. DEFINING FEATURE ENGINEERING FUNCTIONS...\")\n",
    "\n",
    "def create_beneficiary_features(bene_df):\n",
    "    \"\"\"Aggregate beneficiary characteristics\"\"\"\n",
    "    \n",
    "    features = pd.DataFrame()\n",
    "    features['BeneID'] = bene_df['BeneID']\n",
    "    \n",
    "    # Demographics\n",
    "    if 'Gender' in bene_df.columns:\n",
    "        features['Gender'] = bene_df['Gender']\n",
    "    \n",
    "    if 'Race' in bene_df.columns:\n",
    "        features['Race'] = bene_df['Race']\n",
    "    \n",
    "    # Age calculation\n",
    "    if 'DOB' in bene_df.columns:\n",
    "        bene_df['DOB'] = pd.to_datetime(bene_df['DOB'], errors='coerce')\n",
    "        reference_date = pd.to_datetime('2009-12-01')\n",
    "        features['Age'] = (reference_date - bene_df['DOB']).dt.days / 365.25\n",
    "    \n",
    "    # Count chronic conditions\n",
    "    chronic_cols = [col for col in bene_df.columns if 'Chronic' in col]\n",
    "    if chronic_cols:\n",
    "        features['ChronicConditionsCount'] = bene_df[chronic_cols].sum(axis=1)\n",
    "    \n",
    "    # Renal disease indicator\n",
    "    if 'RenalDiseaseIndicator' in bene_df.columns:\n",
    "        features['HasRenalDisease'] = bene_df['RenalDiseaseIndicator'].map({'Y': 1, '0': 0}).fillna(0)\n",
    "    \n",
    "    # Is deceased\n",
    "    if 'DOD' in bene_df.columns:\n",
    "        features['IsDeceased'] = bene_df['DOD'].notna().astype(int)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def aggregate_claims(claims_df, claim_type):\n",
    "    \"\"\"Aggregate claim-level data to provider level\"\"\"\n",
    "    \n",
    "    provider_features = []\n",
    "    \n",
    "    for provider, group in claims_df.groupby('Provider'):\n",
    "        features = {'Provider': provider}\n",
    "        \n",
    "        # Basic claim statistics\n",
    "        features[f'{claim_type}_NumClaims'] = len(group)\n",
    "        features[f'{claim_type}_NumBeneficiaries'] = group['BeneID'].nunique()\n",
    "        features[f'{claim_type}_AvgClaimsPerBeneficiary'] = len(group) / group['BeneID'].nunique()\n",
    "        \n",
    "        # Financial features\n",
    "        if 'InscClaimAmtReimbursed' in group.columns:\n",
    "            features[f'{claim_type}_TotalReimbursed'] = group['InscClaimAmtReimbursed'].sum()\n",
    "            features[f'{claim_type}_AvgReimbursed'] = group['InscClaimAmtReimbursed'].mean()\n",
    "            features[f'{claim_type}_StdReimbursed'] = group['InscClaimAmtReimbursed'].std()\n",
    "            features[f'{claim_type}_MaxReimbursed'] = group['InscClaimAmtReimbursed'].max()\n",
    "            features[f'{claim_type}_MinReimbursed'] = group['InscClaimAmtReimbursed'].min()\n",
    "        \n",
    "        if 'DeductibleAmtPaid' in group.columns:\n",
    "            features[f'{claim_type}_TotalDeductible'] = group['DeductibleAmtPaid'].sum()\n",
    "            features[f'{claim_type}_AvgDeductible'] = group['DeductibleAmtPaid'].mean()\n",
    "        \n",
    "        # Physician statistics\n",
    "        physician_cols = [col for col in group.columns if 'Physician' in col]\n",
    "        if physician_cols:\n",
    "            features[f'{claim_type}_NumUniquePhysicians'] = group[physician_cols].nunique().sum()\n",
    "        \n",
    "        # Diagnosis codes\n",
    "        diag_cols = [col for col in group.columns if 'ClmDiagnosisCode' in col]\n",
    "        if diag_cols:\n",
    "            unique_diagnoses = set()\n",
    "            for col in diag_cols:\n",
    "                unique_diagnoses.update(group[col].dropna().unique())\n",
    "            features[f'{claim_type}_UniqueDiagnoses'] = len(unique_diagnoses)\n",
    "        \n",
    "        # Procedure codes\n",
    "        proc_cols = [col for col in group.columns if 'ClmProcedureCode' in col]\n",
    "        if proc_cols:\n",
    "            unique_procedures = set()\n",
    "            for col in proc_cols:\n",
    "                unique_procedures.update(group[col].dropna().unique())\n",
    "            features[f'{claim_type}_UniqueProcedures'] = len(unique_procedures)\n",
    "        \n",
    "        # Admission duration (for inpatient only)\n",
    "        if claim_type == 'Inpatient' and 'AdmissionDt' in group.columns and 'DischargeDt' in group.columns:\n",
    "            group['AdmissionDt'] = pd.to_datetime(group['AdmissionDt'], errors='coerce')\n",
    "            group['DischargeDt'] = pd.to_datetime(group['DischargeDt'], errors='coerce')\n",
    "            group['LOS'] = (group['DischargeDt'] - group['AdmissionDt']).dt.days\n",
    "            features[f'{claim_type}_AvgLOS'] = group['LOS'].mean()\n",
    "            features[f'{claim_type}_TotalLOS'] = group['LOS'].sum()\n",
    "            features[f'{claim_type}_MaxLOS'] = group['LOS'].max()\n",
    "        \n",
    "        # Claim dates analysis\n",
    "        if 'ClaimStartDt' in group.columns and 'ClaimEndDt' in group.columns:\n",
    "            group['ClaimStartDt'] = pd.to_datetime(group['ClaimStartDt'], errors='coerce')\n",
    "            group['ClaimEndDt'] = pd.to_datetime(group['ClaimEndDt'], errors='coerce')\n",
    "            group['ClaimDuration'] = (group['ClaimEndDt'] - group['ClaimStartDt']).dt.days\n",
    "            features[f'{claim_type}_AvgClaimDuration'] = group['ClaimDuration'].mean()\n",
    "        \n",
    "        provider_features.append(features)\n",
    "    \n",
    "    return pd.DataFrame(provider_features)\n",
    "\n",
    "def aggregate_bene_by_provider(claims_df, bene_features):\n",
    "    \"\"\"Aggregate beneficiary characteristics at provider level\"\"\"\n",
    "    \n",
    "    # Merge claims with beneficiary features\n",
    "    claims_with_bene = claims_df.merge(bene_features, on='BeneID', how='left')\n",
    "    \n",
    "    # Aggregate by provider\n",
    "    agg_dict = {}\n",
    "    \n",
    "    if 'Age' in claims_with_bene.columns:\n",
    "        agg_dict['Age'] = ['mean', 'std', 'min', 'max']\n",
    "    if 'Gender' in claims_with_bene.columns:\n",
    "        agg_dict['Gender'] = 'mean'\n",
    "    if 'ChronicConditionsCount' in claims_with_bene.columns:\n",
    "        agg_dict['ChronicConditionsCount'] = ['mean', 'max', 'sum']\n",
    "    if 'IsDeceased' in claims_with_bene.columns:\n",
    "        agg_dict['IsDeceased'] = 'sum'\n",
    "    if 'HasRenalDisease' in claims_with_bene.columns:\n",
    "        agg_dict['HasRenalDisease'] = 'sum'\n",
    "    \n",
    "    if not agg_dict:\n",
    "        return pd.DataFrame({'Provider': claims_df['Provider'].unique()})\n",
    "    \n",
    "    provider_bene = claims_df.merge(bene_features, on='BeneID', how='left')\\\n",
    "                              .groupby('Provider').agg(agg_dict).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    provider_bene.columns = ['_'.join(col).strip('_') if col[1] else col[0] \n",
    "                             for col in provider_bene.columns.values]\n",
    "    \n",
    "    return provider_bene\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f8b78",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 6. PROCESS TRAINING DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n6. PROCESSING TRAINING DATA...\")\n",
    "\n",
    "print(\"Creating beneficiary features...\")\n",
    "train_bene_features = create_beneficiary_features(train_beneficiary)\n",
    "\n",
    "print(\"Aggregating inpatient claims...\")\n",
    "train_inpatient_features = aggregate_claims(train_inpatient, 'Inpatient')\n",
    "\n",
    "print(\"Aggregating outpatient claims...\")\n",
    "train_outpatient_features = aggregate_claims(train_outpatient, 'Outpatient')\n",
    "\n",
    "print(\"Aggregating beneficiary info by provider (inpatient)...\")\n",
    "train_inpatient_bene = aggregate_bene_by_provider(train_inpatient, train_bene_features)\n",
    "\n",
    "print(\"Aggregating beneficiary info by provider (outpatient)...\")\n",
    "train_outpatient_bene = aggregate_bene_by_provider(train_outpatient, train_bene_features)\n",
    "\n",
    "# Merge all features\n",
    "print(\"Merging all provider features...\")\n",
    "train_provider_data = train_labels.copy()\n",
    "train_provider_data = train_provider_data.merge(train_inpatient_features, on='Provider', how='left')\n",
    "train_provider_data = train_provider_data.merge(train_outpatient_features, on='Provider', how='left')\n",
    "train_provider_data = train_provider_data.merge(train_inpatient_bene, on='Provider', how='left')\n",
    "train_provider_data = train_provider_data.merge(train_outpatient_bene, on='Provider', how='left', \n",
    "                                                 suffixes=('_Inp', '_Out'))\n",
    "\n",
    "# Fill NaN (providers with no claims in one category)\n",
    "train_provider_data = train_provider_data.fillna(0)\n",
    "\n",
    "print(f\"\\n✓ Training provider dataset: {train_provider_data.shape}\")\n",
    "print(f\"✓ Features created: {train_provider_data.shape[1] - 2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf6fd0c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 7. PROCESS TEST DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f71b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n7. PROCESSING TEST DATA...\")\n",
    "\n",
    "print(\"Creating beneficiary features...\")\n",
    "test_bene_features = create_beneficiary_features(test_beneficiary)\n",
    "\n",
    "print(\"Aggregating inpatient claims...\")\n",
    "test_inpatient_features = aggregate_claims(test_inpatient, 'Inpatient')\n",
    "\n",
    "print(\"Aggregating outpatient claims...\")\n",
    "test_outpatient_features = aggregate_claims(test_outpatient, 'Outpatient')\n",
    "\n",
    "print(\"Aggregating beneficiary info by provider (inpatient)...\")\n",
    "test_inpatient_bene = aggregate_bene_by_provider(test_inpatient, test_bene_features)\n",
    "\n",
    "print(\"Aggregating beneficiary info by provider (outpatient)...\")\n",
    "test_outpatient_bene = aggregate_bene_by_provider(test_outpatient, test_bene_features)\n",
    "\n",
    "# Merge all features\n",
    "print(\"Merging all provider features...\")\n",
    "test_provider_data = test_labels.copy()\n",
    "test_provider_data = test_provider_data.merge(test_inpatient_features, on='Provider', how='left')\n",
    "test_provider_data = test_provider_data.merge(test_outpatient_features, on='Provider', how='left')\n",
    "test_provider_data = test_provider_data.merge(test_inpatient_bene, on='Provider', how='left')\n",
    "test_provider_data = test_provider_data.merge(test_outpatient_bene, on='Provider', how='left', \n",
    "                                               suffixes=('_Inp', '_Out'))\n",
    "\n",
    "# Fill NaN\n",
    "test_provider_data = test_provider_data.fillna(0)\n",
    "\n",
    "print(f\"\\n✓ Test provider dataset: {test_provider_data.shape}\")\n",
    "print(f\"✓ Features created: {test_provider_data.shape[1] - 2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fea74",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 8. EXPLORATORY DATA ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n8. EXPLORATORY DATA ANALYSIS...\")\n",
    "\n",
    "# Target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "train_fraud_counts = train_provider_data['PotentialFraud'].value_counts()\n",
    "axes[0].bar(train_fraud_counts.index, train_fraud_counts.values, color=['green', 'red'])\n",
    "axes[0].set_title('Training Set - Fraud Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Potential Fraud')\n",
    "axes[0].set_ylabel('Count')\n",
    "for i, v in enumerate(train_fraud_counts.values):\n",
    "    axes[0].text(i, v + 20, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "test_fraud_counts = test_provider_data['PotentialFraud'].value_counts()\n",
    "axes[1].bar(test_fraud_counts.index, test_fraud_counts.values, color=['green', 'red'])\n",
    "axes[1].set_title('Test Set - Fraud Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Potential Fraud')\n",
    "axes[1].set_ylabel('Count')\n",
    "for i, v in enumerate(test_fraud_counts.values):\n",
    "    axes[1].text(i, v + 20, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/figures/target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: target_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# Fraud comparison - key metrics\n",
    "fraud_yes = train_provider_data[train_provider_data['PotentialFraud'] == 'Yes']\n",
    "fraud_no = train_provider_data[train_provider_data['PotentialFraud'] == 'No']\n",
    "\n",
    "numeric_cols = train_provider_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Select key comparison metrics\n",
    "comparison_metrics = [col for col in [\n",
    "    'Inpatient_TotalReimbursed', 'Outpatient_TotalReimbursed',\n",
    "    'Inpatient_NumClaims', 'Outpatient_NumClaims',\n",
    "    'Age_mean_Inp', 'IsDeceased_sum_Inp'\n",
    "] if col in numeric_cols]\n",
    "\n",
    "if len(comparison_metrics) >= 6:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, col in enumerate(comparison_metrics[:6]):\n",
    "        axes[i].boxplot([fraud_no[col].dropna(), fraud_yes[col].dropna()], \n",
    "                       labels=['No Fraud', 'Fraud'])\n",
    "        axes[i].set_title(col, fontweight='bold')\n",
    "        axes[i].set_ylabel('Value')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('reports/figures/fraud_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"✓ Saved: fraud_comparison.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Correlation heatmap\n",
    "if len(numeric_cols) > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = train_provider_data[numeric_cols].corr()\n",
    "    n_features = min(20, len(numeric_cols))\n",
    "    sns.heatmap(correlation_matrix.iloc[:n_features, :n_features], \n",
    "               annot=False, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('reports/figures/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"✓ Saved: correlation_heatmap.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ea8c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 9. SAVE PROCESSED DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n9. SAVING PROCESSED DATA...\")\n",
    "\n",
    "train_provider_data.to_csv('data/processed_train_provider_data.csv', index=False)\n",
    "test_provider_data.to_csv('data/processed_test_provider_data.csv', index=False)\n",
    "\n",
    "print(\"✓ Saved: processed_train_provider_data.csv\")\n",
    "print(\"✓ Saved: processed_test_provider_data.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA EXPLORATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTraining Dataset Summary:\")\n",
    "print(f\"  Total Providers: {len(train_provider_data)}\")\n",
    "print(f\"  Fraudulent: {len(fraud_yes)} ({len(fraud_yes)/len(train_provider_data)*100:.2f}%)\")\n",
    "print(f\"  Legitimate: {len(fraud_no)} ({len(fraud_no)/len(train_provider_data)*100:.2f}%)\")\n",
    "print(f\"  Total Features: {len(numeric_cols)}\")\n",
    "print(f\"\\nTest Dataset Summary:\")\n",
    "print(f\"  Total Providers: {len(test_provider_data)}\")\n",
    "print(f\"  Total Features: {test_provider_data.shape[1] - 2}\")\n",
    "print(f\"\\nNext Step: Run 02_modeling.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
